{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import convert_json_to_sentence\n",
    "import pandas as pd\n",
    "from dataset import PromptDataset\n",
    "from clip_linear import ClipLinearProbing\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torch\n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Patient is 93 years old, widow of white race, registered on 2013-08-27. Has eating habits rich in no fat. Their last menstruation was at 48 years old and menarche occurred at 14 years old. No information is provided for radiotherapy. The recorded body temperature is 34.50Â°C.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('/home/guillermo/ssd/Github/BreastCATT/prompts/179.0.json')\n",
    "\n",
    "convert_json_to_sentence(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PromptDataset('/home/guillermo/ssd/Github/BreastCATT/prompts', '/home/guillermo/ssd/Github/BreastCATT/patient_labels.json')\n",
    "\n",
    "# Use DataLoader to load the data in batches\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = ClipLinearProbing(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53273/2398609991.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(data[\"label\"][0]).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(278, 1) (278,)\n"
     ]
    }
   ],
   "source": [
    "# Calculate features\n",
    "\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "for data in dataloader:\n",
    "  prompt = data[\"prompt\"][0]  # get the prompt string from the batch\n",
    "  label = torch.tensor(data[\"label\"][0]).float()\n",
    "  \n",
    "  with torch.no_grad():\n",
    "      # model expects a list of prompt(s)\n",
    "      text_features = model([prompt])\n",
    "  all_features.append(text_features)\n",
    "  all_labels.append(label.unsqueeze(0))\n",
    "\n",
    "all_features = (torch.sigmoid(torch.cat(all_features).cpu()) > 0.5).float().numpy()\n",
    "all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "print(all_features.shape, all_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.386160136638885\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean((all_labels == all_features).astype(float)) * 100.\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# problems\n",
    "\n",
    "- max_length of CLIP is 77 (in this library idk if is the same with another version), so I have to truncate the prompt\n",
    "\n",
    "# next steps\n",
    "\n",
    "- linear regression (example here https://github.com/openai/CLIP)\n",
    "- see if the context length can be increased (maybe with CLIP from Hugging Face or OpenCLIP)\n",
    "- disminuir la longitud del prompt en caso de que lo de arriba no se pueda (sin truncarlo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bc-colcaci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
