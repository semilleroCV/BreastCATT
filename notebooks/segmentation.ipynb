{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq5ReFS_zFWE",
        "outputId": "791bcd7c-8582-423d-9689-9aa97542d58a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'BreastCATT'...\n",
            "remote: Enumerating objects: 131, done.\u001b[K\n",
            "remote: Counting objects: 100% (131/131), done.\u001b[K\n",
            "remote: Compressing objects: 100% (99/99), done.\u001b[K\n",
            "remote: Total 131 (delta 58), reused 95 (delta 30), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (131/131), 928.33 KiB | 2.79 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n"
          ]
        }
      ],
      "source": [
        "GIT_TOKEN = \"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\"\n",
        "REPO_URL = f\"https://{GIT_TOKEN}@github.com/semilleroCV/BreastCATT.git\"\n",
        "!git clone $REPO_URL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "sys.path.append(os.path.abspath(\"../\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/sara/miniconda3/envs/colcaci/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "import os\n",
        "\n",
        "# Local directory where you want the checkpoint saved\n",
        "save_path = \"../checkpoints/segmentation\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Download the file\n",
        "checkpoint_path = hf_hub_download(\n",
        "    repo_id=\"SemilleroCV/transunet-breast-cancer\",\n",
        "    filename=\"lucky-sweep-6_0.4937.pth\",\n",
        "    local_dir=save_path\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyW5OfqN5R5R",
        "outputId": "3651d4e7-af5c-4983-aa6c-5bf6f08ec24f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transunet.vit_seg_modeling import VisionTransformer as ViT_seg\n",
        "from transunet.vit_seg_modeling import CONFIGS\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cCntJNYhpsL1"
      },
      "outputs": [],
      "source": [
        "class SegmentationModel(nn.Module):\n",
        "    def __init__(self, img_size: int, n_skip: int, num_classes: int, dir_model: str, device: torch.device, threshold: float = 0.5):\n",
        "        \"\"\"\n",
        "        Initializes the segmentation model with a Vision Transformer (ViT) backbone.\n",
        "        \n",
        "        Args:\n",
        "            img_size (int): The size of the input images.\n",
        "            n_skip (int): The number of skip connections.\n",
        "            num_classes (int): Number of segmentation classes.\n",
        "            dir_model (str): Path to the model weights file.\n",
        "            device (torch.device): The device on which to load the model (CPU or GPU).\n",
        "            threshold (float, optional): Threshold for converting probabilities into binary predictions. Defaults to 0.5.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        self.threshold = threshold\n",
        "\n",
        "        # Fixed configuration; you can try other configurations like \"ViT-B_16\".\n",
        "        self.config_vit = CONFIGS[\"R50-ViT-B_16\"]  # You can try others like \"ViT-B_16\"\n",
        "        self.config_vit.n_classes = num_classes  # Number of classes for binary segmentation\n",
        "        self.config_vit.n_skip = n_skip\n",
        "        self.config_vit.patches.grid = (14, 14)\n",
        "\n",
        "        # Initialize the segmentation model using ViT_seg\n",
        "        self.model = ViT_seg(self.config_vit, img_size=img_size, num_classes=num_classes).to(device)\n",
        "\n",
        "        # Load model weights from file, mapping to the specified device\n",
        "        try:\n",
        "            self.model.load_state_dict(torch.load(dir_model, map_location=device))\n",
        "            print(f\"✅ Weights loaded from {dir_model}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading weights from {dir_model}: {e}\")\n",
        "            raise\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def predict_on_image(self, image_tensor: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Performs prediction on a single image.\n",
        "        \n",
        "        Args:\n",
        "            image_tensor (torch.Tensor): Input image tensor expected to have shape [1, C, H, W].\n",
        "        \n",
        "        Returns:\n",
        "            torch.Tensor: Binary segmentation prediction with shape [C, H, W].\n",
        "        \"\"\"\n",
        "        self.model.eval()  # Set model to evaluation mode\n",
        "        with torch.no_grad():\n",
        "            image_tensor = image_tensor.to(self.device)  # Move the tensor to the appropriate device\n",
        "            logits = self.model(image_tensor)             # Forward pass; output shape: [1, C, H, W]\n",
        "            probs = torch.sigmoid(logits)                   # Convert logits to probabilities using sigmoid\n",
        "\n",
        "            # Convert probabilities to binary mask using the defined threshold\n",
        "            preds = (probs > self.threshold).float()\n",
        "            # Squeeze the batch dimension (assumes batch size is 1)\n",
        "            return preds.squeeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhFyj3Fk5raK",
        "outputId": "dba37a21-e154-4e7d-f220-4006e634e521"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Weights loaded from ../checkpoints/segmentation/lucky-sweep-6_0.4937.pth\n"
          ]
        }
      ],
      "source": [
        "img_size = 224\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "dir_model = \"../checkpoints/segmentation/lucky-sweep-6_0.4937.pth\"\n",
        "segmentador = SegmentationModel(img_size, 3, 1, dir_model, device, threshold=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "n1blYYnX7nJL"
      },
      "outputs": [],
      "source": [
        "data_transform = transforms.Compose([\n",
        "  transforms.Resize((224, 224)),\n",
        "  transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating train split: 100%|██████████| 285/285 [00:00<00:00, 831.70 examples/s]\n",
            "Generating test split: 100%|██████████| 72/72 [00:00<00:00, 676.66 examples/s]\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"SemilleroCV/BreastThermography\", split=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "KwKACKht8A_x"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image saved to sample_image_inferno.png\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load a sample image from the dataset\n",
        "img = dataset[66]['image']  # Select the desired image\n",
        "img = np.array(img, dtype=np.float32)\n",
        "\n",
        "# Normalize the image\n",
        "MAX_TEMPERATURE = 36.44\n",
        "normalized_img = img / MAX_TEMPERATURE  # Normalize to [0, 1]\n",
        "\n",
        "# Apply the colormap and save the image\n",
        "output_path = \"sample_image_inferno.png\"\n",
        "plt.imshow(normalized_img, cmap=\"inferno\")  # Apply the 'inferno' colormap\n",
        "plt.axis('off')  # Remove axes for a clean image\n",
        "plt.savefig(output_path, bbox_inches='tight', pad_inches=0)  # Save the image\n",
        "plt.close()\n",
        "\n",
        "print(f\"Image saved to {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "dodCE6Z48-6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Segmentation output saved to segmentation_output_gray.png\n"
          ]
        }
      ],
      "source": [
        "# Perform segmentation on the image\n",
        "matrix = Image.fromarray(normalized_img)  # Convert numpy array to PIL image\n",
        "matrix = data_transform(matrix)  # Apply transformations\n",
        "matrix = matrix.unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Get the segmentation output\n",
        "output = segmentador.predict_on_image(matrix)\n",
        "\n",
        "# Convert the output to a numpy array\n",
        "output_np = output.cpu().squeeze(0).numpy()  # Remove batch dimension and convert to numpy\n",
        "\n",
        "# Save the segmentation output with a colormap\n",
        "segmentation_output_path = \"segmentation_output_gray.png\"\n",
        "plt.imshow(output_np, cmap='gray')  # Apply the 'inferno' colormap\n",
        "plt.axis('off')  # Remove axes for a clean image\n",
        "plt.savefig(segmentation_output_path, bbox_inches='tight', pad_inches=0)  # Save the image\n",
        "plt.close()\n",
        "\n",
        "print(f\"Segmentation output saved to {segmentation_output_path}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "colcaci",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
